# -*- coding: utf-8 -*-
"""Task1_37.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19v6EGWQhSdoL2wqMOnn5LLdJDLwbeK9J
"""

!pip install scikit-learn spacy gensim sentence-transformers pandas openpyxl
!python -m spacy download en_core_web_sm

!pip uninstall -y numpy pandas scikit-learn
!pip install numpy==1.26.4 pandas==2.2.2 scikit-learn==1.5.0

!pip uninstall -y numpy pandas scikit-learn tsfresh
!pip install numpy==1.26.4 pandas==2.2.2 scikit-learn==1.5.0 spacy==3.7.5 sentence-transformers==3.0.1 openpyxl==3.1.5
!python -m spacy download en_core_web_sm

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
print("Libraries imported successfully!")
print("numpy version:", np.__version__)
print("pandas version:", pd.__version__)
import sklearn
print("scikit-learn version:", sklearn.__version__)

from google.colab import files
uploaded = files.upload()

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# Load the Excel file with all subsheets
excel_file = pd.ExcelFile('DL_Research_Work_37.xlsx')

# Initialize a DataFrame for the Author_Profiles summary
author_profiles = pd.DataFrame(columns=['Researcher', 'Top Research Themes'])

# Process each researcher's subsheet
for sheet_name in excel_file.sheet_names:
    # Skip any non-researcher sheets (e.g., summary sheets if they exist)
    if sheet_name not in ['Author_Profiles', 'Author_diversity']:
        # Load the subsheet
        df = pd.read_excel(excel_file, sheet_name=sheet_name)

        # Combine abstracts, excluding missing ones
        abstracts = df['Abstract'].dropna().tolist()
        if not abstracts:  # Skip if no abstracts
            print(f"No abstracts found for {sheet_name}. Skipping...")
            continue
        combined_text = " ".join(abstracts)

        # Extract top keywords using TF-IDF
        vectorizer = TfidfVectorizer(stop_words='english', max_features=10)
        tfidf_matrix = vectorizer.fit_transform([combined_text])
        keywords = vectorizer.get_feature_names_out().tolist()

        # Add to Author_Profiles
        author_profiles = pd.concat([author_profiles, pd.DataFrame({
            'Researcher': [sheet_name],
            'Top Research Themes': [", ".join(keywords)]
        })], ignore_index=True)

# Save the Author_Profiles summary to the Excel file
with pd.ExcelWriter('DL_Research_Work_37.xlsx', mode='a', if_sheet_exists='replace') as writer:
    author_profiles.to_excel(writer, sheet_name='Author_Profiles', index=False)

print("Author_Profiles summary created.")

from sentence_transformers import SentenceTransformer, util
import numpy as np
import pandas as pd

# Load the Sentence-BERT model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Load the Excel file with the specified engine
excel_file = pd.ExcelFile('DL_Research_Work_37.xlsx', engine='openpyxl')

# Initialize a DataFrame for the Author_diversity summary
author_diversity = pd.DataFrame(columns=['Researcher', 'Average Similarity', 'Diversity Score'])

# Process each researcher's subsheet
for sheet_name in excel_file.sheet_names:
    if sheet_name not in ['Author_Profiles', 'Author_diversity']:
        df = pd.read_excel(excel_file, sheet_name=sheet_name, engine='openpyxl')
        abstracts = df['Abstract'].dropna().tolist()

        # Skip if there are fewer than 2 abstracts (can't compute similarity)
        if len(abstracts) < 2:
            print(f"Fewer than 2 abstracts for {sheet_name}. Skipping...")
            continue

        # Compute embeddings
        embeddings = model.encode(abstracts, convert_to_tensor=True)

        # Compute pairwise cosine similarity
        similarity_matrix = util.cos_sim(embeddings, embeddings).cpu().numpy()

        # Calculate average similarity (excluding self-similarity)
        n = len(abstracts)
        total_sim = np.sum(similarity_matrix) - n  # Subtract diagonal
        avg_similarity = total_sim / (n * (n - 1))

        # Assign diversity score
        if avg_similarity > 0.7:
            diversity = "Low Diversity"
        elif avg_similarity > 0.4:
            diversity = "Medium Diversity"
        else:
            diversity = "High Diversity"

        # Add to Author_diversity
        author_diversity = pd.concat([author_diversity, pd.DataFrame({
            'Researcher': [sheet_name],
            'Average Similarity': [avg_similarity],
            'Diversity Score': [diversity]
        })], ignore_index=True)

# Save the Author_diversity summary to the Excel file
with pd.ExcelWriter('DL_Research_Work_37.xlsx', mode='a', if_sheet_exists='replace', engine='openpyxl') as writer:
    author_diversity.to_excel(writer, sheet_name='Author_diversity', index=False)

print("Author_diversity summary created.")

from google.colab import files
files.download('DL_Research_Work_37.xlsx')

# Save the themes script
with open('analyze_themes.py', 'w') as f:
    f.write("")

